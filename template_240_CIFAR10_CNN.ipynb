{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fc3d57f",
   "metadata": {
    "id": "q4RMbkolIgZP"
   },
   "source": [
    "# 240. CIFAR-10 을 이용한 CNN 구축\n",
    "\n",
    "- **CNN**을 학습하여 CIFAR-10 데이터베이스의 이미지를 분류합니다.\n",
    "\n",
    "<img src='https://production-media.paperswithcode.com/datasets/CIFAR-10-0000000431-b71f61c0_U5n3Glr.jpg' width=600 />\n",
    "\n",
    "\n",
    "- mean, std ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) 로 normalize 된 image 의 unnormalization 방법\n",
    "    - image = image * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9fe3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3a843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c806c0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e78c5097",
   "metadata": {
    "id": "RXokErjxgyjY"
   },
   "source": [
    "## Data Download 및 Data Loader 를 이용하여 Train, Validation data 준비\n",
    "\n",
    "transforms.ToTensor()의 주요 특징:\n",
    "\n",
    "1) 데이터 타입 변환: PIL 이미지나 NumPy ndarray를 torch.FloatTensor로 변환  \n",
    "2) 스케일링: 이미지의 픽셀 값 범위를 [0, 255]에서 [0.0, 1.0]으로 스케일링  \n",
    "3) 차원 재배열: PyTorch에서는 이미지 데이터를 [C, H, W] 형식(채널, 높이, 너비)으로 처리하므로 입력 이미지 데이터의 차원을 이 형식으로 자동 재배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf36192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지 데이터에 대한 변환(transform) 조합을 정의\n",
    "# 이 변환은 이미지 데이터를 증강(augmentation)하고 전처리하는 과정을 포함합니다.\n",
    "# CIFAR10 훈련 데이터셋을 다운로드하고, 위에서 정의한 변환을 적용\n",
    "# CIFAR10 테스트 데이터셋을 다운로드하고, 위에서 정의한 변환을 적용\n",
    "# DataLoader를 사용하여 훈련 데이터셋과 테스트 데이터셋을 배치로 로드합니다.\n",
    "# shuffle=True는 훈련 데이터 로딩 시 데이터를 무작위로 섞어 오버피팅을 방지하는 데 도움이 됩니다.\n",
    "# 테스트 데이터 로더에서는 데이터를 섞지 않습니다(shuffle=False)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3c3b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11325730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f67d4a50",
   "metadata": {
    "id": "mwlI9nSwg5j-"
   },
   "source": [
    "### 일부 Data 시각화\n",
    "\n",
    "- matplotlib 은 channel 위치가 last 이므로 transpose(1, 2, 0) 로 image 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b679e982",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # np.transpose 함수를 사용하여 'x' 텐서의 차원을 재배열\n",
    "    # (1, 2, 0)은 채널 차원을 마지막으로 이동시키고, 높이와 너비 차원을 앞으로 가져옵니다.\n",
    "    # 이 형식은 matplotlib와 같은 일부 라이브러리에서 이미지를 표시할 때 요구되는 형식입니다.\n",
    "    # * 0.5 + 0.5 연산은 정규화를 되돌려 픽셀 값을 원본 범위(0~1)로 unnormalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac1ba2c",
   "metadata": {
    "id": "6SdZUr6fIgZa"
   },
   "source": [
    "## Model build\n",
    "\n",
    "### Custom Model\n",
    "\n",
    "- Output Size = (W - F + 2P) / S + 1  \n",
    "- output_size / Maxpool(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870e35e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_size(W, F, P, S, poolsize=1):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d247bc36",
   "metadata": {
    "id": "qaFdOdKn4nIW"
   },
   "source": [
    "input image size : (32, 32)\n",
    "kernel size : 3\n",
    "padding : 1\n",
    "stride : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02899c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4408840",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 3개의 입력 채널을 받아 16개의 출력 채널을 생성\n",
    "        # 커널 크기는 3, 패딩은 1로 설정하여 입력 이미지의 크기를 유지합니다.\n",
    "        # 16개의 입력 채널을 받아 32개의 출력 채널을 생성\n",
    "        # 32개의 입력 채널을 받아 64개의 출력 채널을 생성\n",
    "        # 첫 번째 완전 연결 층을 정의합니다. 입력 특징의 수는 4*4*64, 출력 특징의 수는 256입니다.\n",
    "        # 두 번째 완전 연결 층을 정의합니다. 10개의 출력 클래스에 대응합니다.\n",
    "    def forward(self, x):\n",
    "        # 합성곱 층과 배치 정규화, ReLU 활성화 함수, 최대 풀링을 차례로 적용\n",
    "        # 특징 맵을 1차원으로 평탄화\n",
    "        # 드롭아웃 적용\n",
    "        # 완전 연결 층과 배치 정규화, ReLU 활성화 함수 적용\n",
    "        # 최종 출력 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02b8d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae99b844",
   "metadata": {
    "id": "hRxrKLRI9F-L"
   },
   "source": [
    "`model.forward(train_data[0][0].unsqueeze(0).to(device))`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a83cdc",
   "metadata": {
    "id": "utACyzFKhGaM"
   },
   "source": [
    "### nn.Sequential 이용\n",
    "\n",
    "\n",
    "- ``torch.nn`` 에는 코드를 간단히 사용할 수 있는 또 다른 편리한 클래스인\n",
    "[Sequential](https://pytorch.org/docs/stable/nn.html#torch.nn.Sequential) 이 있습니다.  \n",
    "\n",
    "- ``Sequential`` 객체는 그 안에 포함된 각 모듈을 순차적으로 실행합니다. 이것은 신경망을 작성하는 더 간단한 방법입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d751b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Sequential을 사용하여 순차적 모델을 정의합니다. 이 방식은 각 레이어를 순서대로 쌓아 올립니다.\n",
    "    #  3개의 입력 채널(예: RGB 이미지)을 받아 16개의 출력 채널 생성\n",
    "    # 커널 크기는 3, 스트라이드는 1, 패딩은 1로 설정\n",
    "    # 16개의 채널에 대해 배치 정규화 수행\n",
    "    # 활성화 함수로 ReLU 사용\n",
    "    # 맥스 풀링 레이어: 커널 크기와 스트라이드를 2로 설정\n",
    "    # 6개의 입력 채널을 받아 32개의 출력 채널 생성\n",
    "    # 32개의 채널에 대해 배치 정규화 수행\n",
    "    # 32개의 입력 채널을 받아 64개의 출력 채널 생성\n",
    "    # 64개의 채널에 대해 배치 정규화 수행\n",
    "    # 텐서를 1차원으로 평탄화\n",
    "    # 드롭아웃을 적용하여 과적합 방지\n",
    "    # 평탄화된 텐서를 받아 256개의 뉴런을 가진 레이어로 연결\n",
    "    # 완전 연결 레이어의 배치 정규화\n",
    "    # 10개의 출력을 가진 레이어로 클래스 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949f62ae",
   "metadata": {
    "id": "G-cUi6OjIgZc"
   },
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4c1f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b84346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb6b110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 모델의 파라미터 수가 동일함을 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726d3a38",
   "metadata": {
    "id": "38FnXHXlIgZc"
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b093b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c9d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 에폭별 훈련 및 검증 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43615d36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "946d8d56",
   "metadata": {
    "id": "131T7vCmIgZe"
   },
   "source": [
    "### Model 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461f4af",
   "metadata": {
    "id": "ZKdyh4-6hoy3"
   },
   "source": [
    "### model 이 어떤 image 들을 잘 맞추고 혹은 틀렸는지 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfe6868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 데이터셋을 배치 단위로 순회\n",
    "# 예측값과 실제 레이블이 일치하는 경우의 인덱스를 찾음\n",
    "# 예측값과 실제 레이블이 불일치하는 경우의 인덱스를 찾음\n",
    "# 정확도 계산: 정확한 예측의 수를 전체 예측의 수로 나눈 후 100을 곱하여 백분율로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705fb300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef5a720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정확한 예측의 인덱스에서 처음 9개를 순회합니다.\n",
    " # 잘못된 예측의 인덱스에서 처음 9개를 순회합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ceea1a",
   "metadata": {
    "id": "-nJ765fqh-tC"
   },
   "source": [
    "## Saving and loading the model\n",
    "\n",
    "### Save and load the model via state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ae4fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a79b4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Net' 클래스로부터 모델 인스턴스 생성\n",
    "# 'load_state_dict()' 메서드를 사용하여 로드한 가중치를 현재 모델 인스턴스에 적용합니다.\n",
    "# 'eval()' 메서드는 모델을 평가/테스트 모드로 설정하여, 드롭아웃, 배치 정규화 등이\n",
    "# 학습 모드와는 다르게 동작하도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf29e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c3717e9",
   "metadata": {
    "id": "O9NDbhuhsecS"
   },
   "source": [
    "### Save and load entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dd9a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c6abdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ebf6099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489ef86b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
