{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4185bd23",
   "metadata": {
    "id": "CssVKVSJuxYY"
   },
   "source": [
    "\n",
    "# 270. 컴퓨터 비전(Vision)을 위한 전이학습(Transfer Learning)\n",
    "=======================================================\n",
    "\n",
    "- 실제로 충분한 크기의 데이터셋을 갖추기는 상대적으로 드물기 때문에, (무작위 초기화를 통해) 처음부터 합성곱 신경망(Convolutional Network) 전체를 작성하는 경우는 매우 적다.   \n",
    "\n",
    "\n",
    "- 대신, 매우 큰 데이터셋(예. 100가지 분류에 대해 120만개의 이미지가 포함된 ImageNet)에서 합성곱 신경망(ConvNet)을 미리 학습한 후, 이 합성곱 신경망을 관심있는 작업을 위한 초기 설정 또는 고정된 특징 추출기(fixed feature extractor)로 사용\n",
    "\n",
    "### 전이학습의 2 가지 시나리오:\n",
    "\n",
    "-  **합성곱 신경망의 미세조정(finetuning)**: 신경망을 ImageNet 등으로 미리 학습한 신경망으로 초기화하고 parameter 미세 조정  \n",
    "\n",
    "\n",
    "-  **고정된 특징 추출기로써의 합성곱 신경망**: 마지막 완전 연결층을 제외한 모든 신경망의 가중치를 고정. 마지막의 완전 연결층은 새로운 무작위의 가중치를 갖는 계층으로 대체되어 이 계층만 학습.  \n",
    "\n",
    "\n",
    "### torch 제공 pre-trained models\n",
    "```\n",
    "    import torchvision.models as models  \n",
    "    \n",
    "    resnet18 = models.resnet18()  \n",
    "    alexnet = models.alexnet()  \n",
    "    vgg16 = models.vgg16()  \n",
    "    squeezenet = models.squeezenet1_0()  \n",
    "    densenet = models.densenet161()  \n",
    "    inception = models.inception_v3()  \n",
    "    googlenet = models.googlenet()  \n",
    "    shufflenet = models.shufflenet_v2_x1_0()  \n",
    "    mobilenet = models.mobilenet_v2()  \n",
    "    resnext50_32x4d = models.resnext50_32x4d()  \n",
    "    wide_resnet50_2 = models.wide_resnet50_2()  \n",
    "    mnasnet = models.mnasnet1_0()  \n",
    "```   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172f789d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로그램 실행 중 사용할 수 있는 임시 폴더 생성\n",
    "# 블록 벗어나면 자동 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cabd5e",
   "metadata": {
    "id": "gowJPapAuxYb"
   },
   "source": [
    "데이터 불러오기\n",
    "---------------\n",
    "\n",
    "- **개미** 와 **벌** 을 분류하는 이진 분류 모델을 학습\n",
    "    - 대략 120장 정도의 훈련 이미지와, 75장의 검증용 이미지를 이용\n",
    "    - 전이학습을 통해 소량의 데이터로도 일반화 가능\n",
    "    - ImageNet의 일부 data 이용\n",
    "\n",
    "-  데이터를 [여기](https://download.pytorch.org/tutorial/hymenoptera_data.zip)\n",
    "   에서 다운로드 받아 현재 디렉토리에 압축을 푼다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34d8f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 증가(augmentation) 및 ResNet 에 적합한 normalization 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aef243",
   "metadata": {
    "id": "nTHEd8-EuxYe"
   },
   "source": [
    "# ImageFolder 라이브러리\n",
    "\n",
    "- 계층적인 폴더 구조를 가지고 있는 데이터셋을 불러올 때 사용할 수 있다. 각 이미지들이 자신의 레이블(Label) 이름으로 된 폴더 안에 들어가 있는 구조라면, ImageFolder 라이브러리를 이용하여 이를 바로 불러와 객체로 만들면 된다.\n",
    "\n",
    "ImageFolder를 사용하기 위해선 가장 먼저 수집된 데이터의 폴더구조를 아래와 같이 설계해야한다  \n",
    "\n",
    "최상위 경로 아래에 각각의 class name을 가지는 폴더를 구성하고 그 하위경로에 이미지가 저장되어있는 방식이다.\n",
    "```\n",
    "root_dir\n",
    "    | --- ants/\n",
    "    |      |-- 0001.jpg\n",
    "    |      |-- 0002.jpg\n",
    "    |      |-- ...\n",
    "    | --- bees/\n",
    "    |      |-- 0001.jpg\n",
    "    |      |-- 0002.jpg\n",
    "    |      |-- ...\n",
    "    | --- rabbit/\n",
    "    |      |--...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d15c89b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80cfe215",
   "metadata": {
    "id": "DE9IcXkKuxYh"
   },
   "source": [
    "### `datasets.ImageFolder(folder, transform)` data loader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364b350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c678641",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36f77068",
   "metadata": {
    "id": "1lDvPnhbuxYp"
   },
   "source": [
    "### 일부 이미지 시각화하기\n",
    "\n",
    "- `torchvision.utils.make_grid(tensor)`  \n",
    "  - `tensor (Tensor 또는 list)`: 4차원 텐서 `(B x C x H x W)` 형태의 미니 배치 텐서 또는 같은 크기의 이미지 리스트입니다. (여기서 B는 이미지 개수, C는 채널 수, H와 W는 이미지의 높이와 너비)  \n",
    "  - `nrow (int, 선택)`: 한 줄에 표시할 이미지 개수입니다. 최종 그리드는 `(B / nrow, nrow)` 형태가 됩니다. 기본값은 8입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb20814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    # 입력 텐서 차원을 재배열. PyTorch - [C, H, W], matplotlib - [H, W, C]\n",
    "    # 이미지를 정규화할 때 사용된 평균과 표준편차를 정의 - 모델이 학습될 때 사용된 값들\n",
    "    # 정규화된 이미지 데이터를 원래의 범위로 되돌립니다.\n",
    "    # np.clip 함수를 사용하여 이미지 데이터의 값이 0과 1 사이로 제한됩니다.\n",
    "    # 이미지 위에 제목 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194ac1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터 로더에서 첫 번째 배치를 가져옵니다.\n",
    "# 가져온 이미지 배치를 그리드 형태로 만듭니다.\n",
    "# 만들어진 이미지 그리드를 시각화합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa173cb",
   "metadata": {
    "id": "6LOX-IboLCCD"
   },
   "source": [
    "Model Train\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f263964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    # 임시 디렉토리 생성 (학습 중 가장 성능이 좋은 모델을 여기에 저장)\n",
    "        # 현재 모델의 초기 상태를 저장 (기준점)\n",
    "        # 에폭 반복\n",
    "            # 각 에폭은 훈련(Train)과 검증(Validation) 두 단계로 구성됨\n",
    "                # 현재 단계의 데이터셋을 반복\n",
    "                    # 이전 단계의 gradient 초기화\n",
    "                    # 순전파 수행\n",
    "                    # 학습 단계일 때만 gradient 기록\n",
    "                        # 학습 단계일 경우 역전파 및 최적화 수행\n",
    "                    # 손실과 정확도 누적 계산\n",
    "                # 학습 단계일 경우 스케줄러로 learning rate 갱신\n",
    "                # epoch의 평균 손실과 정확도 계산\n",
    "                # 검증 단계에서 정확도가 최고 기록이면 모델 저장\n",
    "        # 전체 학습 시간 계산 및 출력\n",
    "        # 가장 정확도가 높았던 모델의 가중치 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d8971",
   "metadata": {
    "id": "M6scWVr3LMCu"
   },
   "source": [
    "모델 예측 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc22f1e",
   "metadata": {
    "id": "odcUHY7jLTKO"
   },
   "source": [
    "## 방법 1. pre-trained  ConvNet 신경망 전체를 미세조정(finetuning)\n",
    "\n",
    "- 미리 학습된 모델을 불러온 후 마지막의 완전 연결층 만을 새로 작성하고 **전체 parameter** 를 fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ae837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 ResNet-18 모델을 불러옴 (ImageNet 학습 가중치 사용)\n",
    "# ResNet의 마지막 fully-connected 층(fc)의 입력 feature 수 추출\n",
    "# 출력 클래스 수를 2개로 설정\n",
    "# 모델을 device로 이동\n",
    "# 손실 함수 설정\n",
    "# 옵티마이저 설정 (SGD: 확률적 경사하강법, 학습률 0.001, 모멘텀 0.9)\n",
    "# 학습률 스케줄러 설정: 7 에폭마다 학습률을 0.1배씩 감소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfeb8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 함수(train_model)를 호출하여 모델 학습 시작"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2d3ae9",
   "metadata": {
    "id": "lJS2QRAEhu53"
   },
   "source": [
    "# 학습된 모델(model_ft)을 시각화하여 예측 결과를 확인\n",
    " - 검증 데이터셋에서 일부 이미지를 가져와 모델이 예측한 클래스 이름과 함께 이미지 출력\n",
    " -  총 6개의 이미지를 보여줌 (기본값 num_images=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c02e0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e212691",
   "metadata": {
    "id": "HrbdZcqeLlco"
   },
   "source": [
    "## 방법 2 : Pre-trained ConvNet을 weight 고정된 특징 추출기로 사용\n",
    "\n",
    "- 미리 학습된 모델을 불러온 후 마지막의 **완전 연결층 만을 새로 작성**하되 마지막 계층을 제외한 **신경망의 모든 부분을 고정** (``requires_grad = False`` 로 설정)하여 ``backward()`` 중에 gradient가 계산되지 않도록 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb70c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습된 ResNet-18 모델 로드 (ImageNet 가중치 사용)\n",
    "# 모든 파라미터의 requires_grad 값을 False로 설정하여 고정시킴\n",
    "# → 기존 가중치는 학습되지 않음 (feature extractor로만 사용)\n",
    "# 새로 정의할 fully-connected 레이어(fc)의 입력 특징 수 추출\n",
    "# 출력층(fc)을 이진 분류용으로 교체 (출력 클래스 수 = 2)\n",
    "# 새로 생성한 fc 레이어의 파라미터는 기본적으로 requires_grad=True → 학습 가능\n",
    "# 손실 함수 설정\n",
    "# 옵티마이저 설정:\n",
    "# 이전과 달리 model_conv 전체가 아닌 fc 레이어의 파라미터만 최적화 대상\n",
    "# 즉, 출력층만 학습되고 나머지 레이어는 고정됨\n",
    "# 학습률 스케줄러 설정: 7 에폭마다 학습률을 0.1배씩 감소"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65b2c9a",
   "metadata": {
    "id": "sfemJPPuLuhY"
   },
   "source": [
    "### 훈련 및 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3822a0d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7ac5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델(model_conv)을 이용해 검증 데이터셋에서 예측 결과를 시각화\n",
    "# 인터랙티브 모드를 끄고 명시적으로 plt.show() 호출할 때까지 기다리도록 설정\n",
    "# 누적된 그래프/이미지 시각화를 화면에 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c9d72",
   "metadata": {
    "id": "G0h7zrS6L3mF"
   },
   "source": [
    "### 사용자 정의 이미지에 대한 추론\n",
    "훈련된 모델을 사용하여 사용자 정의 이미지에 대한 예측을 하고 예측된 클래스 레이블을 이미지와 함께 시각화합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7c03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_conv\n",
    "# 이미지 열기\n",
    "# 검증 데이터에 사용된 변환(transform) 적용\n",
    "# 배치 차원을 추가 (모델 입력 형태: [1, C, H, W])\n",
    "# 추론 실행 (gradient 비활성화 → 메모리, 속도 효율적)\n",
    "# 시각화: 2x2 서브플롯 중 첫 번째 칸에 이미지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebab34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 평가 모드로 설정\n",
    "        # 출력값 중 최대값을 가진 인덱스를 예측값으로 선택\n",
    "        # 예측값을 predictions 리스트에 추가\n",
    "        # 실제 레이블을 labels 리스트에 추가\n",
    "    # 예측값과 실제 레이블이 일치하는 인덱스를 찾음\n",
    "    # 예측값과 실제 레이블이 불일치하는 인덱스를 찾음\n",
    "# 정확도를 계산하여 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf36c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
