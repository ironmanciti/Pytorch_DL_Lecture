{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a88e809",
   "metadata": {
    "id": "PoGXBuf9bs5t"
   },
   "source": [
    "# 230. mnist dataset 손글씨 인식 - LeNet\n",
    "\n",
    "- CNN 을 이용한 mnist dataset 손글씨 인식  \n",
    "- Yan LeCunn 이 1998 년 발표한 LeNet-5 을 Pytorch 로 customize 하여 재현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e348bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4b9e87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ebbf1498",
   "metadata": {},
   "source": [
    "transforms.ToTensor()의 주요 특징:\n",
    "\n",
    "1) 데이터 타입 변환: PIL 이미지나 NumPy ndarray를 torch.FloatTensor로 변환  \n",
    "2) 스케일링: 이미지의 픽셀 값 범위를 [0, 255]에서 [0.0, 1.0]으로 스케일링  \n",
    "3) 차원 재배열: PyTorch에서는 이미지 데이터를 [C, H, W] 형식(채널, 높이, 너비)으로 처리하므로 입력 이미지 데이터의 차원을 이 형식으로 자동으로 재배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce51cd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.Compose는 여러 변환(transform)을 함께 결합할 때 사용됩니다.\n",
    "    # 정규화를 수행합니다. 평균(mean)은 0.1, 표준편차(std)는 0.3으로 설정\n",
    "    # 이 경우는 단일 채널(예: 흑백 이미지)의 이미지를 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d550f468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f58d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6b98a54",
   "metadata": {
    "id": "LVq2yIVrdv9j"
   },
   "source": [
    "- Data 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e27c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cec709ac",
   "metadata": {
    "id": "Va0vYqSXbs55"
   },
   "source": [
    "### Dataset Loader 생성\n",
    "- Train dataset 을 Train 와 Validation 으로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e97602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 훈련 데이터의 20%를 검증 데이터로 설정\n",
    "# 훈련 데이터셋의 총 길이\n",
    "# 0부터 num_train-1까지의 인덱스 생성\n",
    "# 인덱스를 무작위로 섞습니다. 이를 통해 데이터셋의 무작위성을 보장합니다.\n",
    "# 검증 세트의 크기에 해당하는 분할 지점 계산\n",
    "# 계산된 분할 지점을 기준으로 훈련 세트와 검증 세트의 인덱스를 나눕니다.\n",
    "# split 이후의 인덱스는 훈련 세트, split 이전의 인덱스는 검증 세트로 사용됩니다.\n",
    "# 훈련 세트와 검증 세트의 인덱스를 사용하여 SubsetRandomSampler 객체를 생성합니다.\n",
    "# 이 샘플러는 DataLoader에 전달될 때, 지정된 인덱스에 해당하는 데이터만을 무작위로 추출하는 데 사용됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bb28de",
   "metadata": {
    "id": "1AFzg8HAd_0_"
   },
   "source": [
    "- train, validation, test dataset 으로 3 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23135d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로더를 생성합니다. 이 DataLoader는 앞서 정의한 train_sampler를 사용하여\n",
    "# 지정된 인덱스에 따라 훈련 데이터셋에서 무작위로 데이터를 샘플링합니다.\n",
    "# 이렇게 함으로써 훈련 과정에서의 데이터 다양성을 증가시킬 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33941bd1",
   "metadata": {
    "id": "mRMQpq7abs57"
   },
   "source": [
    "## Model build\n",
    "\n",
    "<img src=\"https://d2l.ai/_images/lenet.svg\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ccbfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "    def forward(self, x):\n",
    "#         print(x.shape)\n",
    "#         return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6058c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96f6262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'train_loader'에서 첫 번째 배치를 가져옵니다.\n",
    "# 'iter()' 함수를 사용하여 반복 가능한 객체에서 반복자(iterator)를 생성하고,\n",
    "# 'next()' 함수를 사용하여 첫 번째 요소(배치)를 추출합니다.\n",
    "# 이 때, [0]은 첫 번째 배치의 데이터(특성) 부분을 의미합니다.\n",
    "# 배치의 두 번째 요소는 레이블(label)이 될 것입니다.\n",
    "# 출력된 형태는 [배치 크기, 채널 수, 높이, 너비] 형태를 갖습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfc1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델에 첫 번째 배치의 데이터를 전달하여 순방향(forward) 연산을 수행합니다.\n",
    "# 'train_loader'에서 첫 번째 배치를 가져오기 위해 iter()와 next() 함수를 사용합니다.\n",
    "# next(iter(train_loader))[0]는 첫 번째 배치의 데이터 부분을 의미하며,\n",
    "# 이 데이터는 모델의 입력으로 사용됩니다.\n",
    "# 모델의 forward 메서드를 호출하여 첫 번째 배치 데이터에 대한 예측을 수행합니다.\n",
    "# 분류 문제의 경우 출력은 각 클래스에 속할 확률을 나타낼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a31cdca",
   "metadata": {
    "id": "EFsqOK7zfGyn"
   },
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27cad1d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a083bbb2",
   "metadata": {
    "id": "aObbLMxnbs5-"
   },
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3328298e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db40bab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cd293",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 에폭별 훈련 및 검증 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e501df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f644937",
   "metadata": {
    "id": "SRPlwCgebs5_"
   },
   "source": [
    "## Model 평가 - Test set 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca78fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 로더를 통해 테스트 데이터셋의 배치를 순회\n",
    "    # 예측 결과와 실제 레이블을 CPU로 이동 후 numpy 배열로 변환하여 리스트에 추가\n",
    "# 예측값과 실제 레이블이 일치하는 인덱스 추출\n",
    "# 예측값과 실제 레이블이 일치하지 않는 인덱스 추출\n",
    "# 정확도 계산: 정확한 예측의 수를 전체 예측의 수로 나눈 후 백분율로 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a479ae",
   "metadata": {
    "id": "FVUpUTXVipQI"
   },
   "source": [
    "## Category 별 분류 성능 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe935160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82d1ec4d",
   "metadata": {
    "id": "6JOCwrdBbs6C"
   },
   "source": [
    "# 실습 : fashion MNIST 를 이용하여 위와 동일한 작업\n",
    "\n",
    "Label\tClass\n",
    "\n",
    "0\tT-shirt/top  \n",
    "1\tTrouser  \n",
    "2\tPullover  \n",
    "3\tDress  \n",
    "4\tCoat  \n",
    "5\tSandal  \n",
    "6\tShirt  \n",
    "7\tSneaker  \n",
    "8\tBag  \n",
    "9\tAnkle boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33686c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9859c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28be60a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e91e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e9ffe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
