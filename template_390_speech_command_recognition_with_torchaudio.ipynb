{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4a2b635",
   "metadata": {
    "id": "Qu8nR1-Z0i-u"
   },
   "source": [
    "# TORCHAUDIO 이용 음성 인식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897911b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8173d60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef4f69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f46336c",
   "metadata": {
    "id": "MeCNH9Sh0i--"
   },
   "source": [
    "데이터 세트 가져오기\n",
    "---------------------\n",
    "\n",
    "torchaudio를 사용하여 데이터 세트를 다운로드하고 나타냅니다. 여기에서는 서로 다른 사람들이 말한 35 개 명령의 데이터세트 인 SpeechCommands 를 사용 합니다.  SPEECHCOMMANDS는 이 데이터세트의 torch.utils.data.Dataset 버전입니다. 이 데이터세트에서 모든 오디오 파일의 길이는 약 1 초입니다 (따라서 약 16000 time frame 길이 / 16kHz(16,000Hz)).\n",
    "\n",
    "실제 로딩 및 포맷 단계는 데이터 포인트에 액세스 할 때 발생하며 torchaudio는 오디오 파일을 텐서로 변환합니다. 오디오 파일을 직접로드하려면torchaudio.load()를 사용할 수 있습니다. 오디오 파일의 샘플링 주파수 (SpeechCommands의 경우 16kHz)와 함께 새로 생성된 텐서를 포함하는 튜플을 반환합니다.\n",
    "\n",
    "데이터 세트로 돌아가서 training, validation, testing 하위 집합으로 분할하는 subclass를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b1dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SubsetSC 클래스는 SPEECHCOMMANDS 데이터셋을 상속하여,\n",
    "# 학습, 테스트, 검증용 하위 집합으로 나누기 위한 클래스\n",
    "class SubsetSC(SPEECHCOMMANDS):\n",
    "    def __init__(self, subset: str = None):\n",
    "        # 부모 클래스(SPEECHCOMMANDS)를 호출하며 데이터셋을 다운로드함\n",
    "        # 파일에서 리스트를 로드하는 함수\n",
    "        def load_list(filename):\n",
    "            # 파일 경로를 설정\n",
    "            # 파일을 열어 각 줄에 있는 파일 경로를 리스트로 변환\n",
    "        # 검증용 데이터셋을 로드할 경우\n",
    "        # 테스트용 데이터셋을 로드할 경우\n",
    "        # 학습용 데이터셋을 로드할 경우\n",
    "            # 검증 및 테스트 리스트에서 제외할 항목들을 설정\n",
    "            # 학습용 데이터는 검증 및 테스트 데이터에 포함되지 않은 파일들로 구성\n",
    "# 학습과 테스트 데이터를 생성. 이 튜토리얼에서는 검증 데이터를 사용하지 않음\n",
    "# 학습 데이터셋의 첫 번째 항목을 가져옴 (waveform, 샘플링 레이트, 레이블, 화자 ID, 발화 번호)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5170b3c",
   "metadata": {
    "id": "lCFjhB3z0i-_"
   },
   "source": [
    "SPEECHCOMMANDS 데이터 세트의 데이터 포인트는 파형 (오디오 신호), 샘플 속도, 발화 (레이블), 화자의 ID, 발화 수로 구성된 튜플입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f037e6",
   "metadata": {
    "id": "6IKagsojpLBy"
   },
   "source": [
    "### torchaudio  사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e339ec6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3967e933",
   "metadata": {
    "id": "kwS_JMEr0i_B"
   },
   "source": [
    "데이터 세트에서 사용할 수있는 라벨 목록을 찾아 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40b4d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d967768",
   "metadata": {
    "id": "ufmIVmdu0i_D"
   },
   "source": [
    "오디오 레이블은 사용자가 말하는 명령입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ddde01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea64a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80cd631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc7ab64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce6769",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b766d90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eecca884",
   "metadata": {
    "id": "O_CmcCtC0i_H"
   },
   "source": [
    "데이터 포맷\n",
    "-------------------\n",
    "\n",
    "파형의 경우 분류 능력을 너무 많이 잃지 않고 빠른 처리를 위해 오디오를 다운 샘플링합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a3d920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 새로운 샘플링 속도를 8000Hz로 설정\n",
    "# 원래 샘플링 속도에서 새로운 샘플링 속도로 오디오를 리샘플링하는 변환 설정\n",
    "# 파형(waveform)에 리샘플링 변환을 적용하여 변환된 파형 생성\n",
    "# 리샘플링된 오디오를 새로운 샘플링 속도로 재생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904dd8ec",
   "metadata": {
    "id": "dtaal0LO0i_I"
   },
   "source": [
    "레이블 목록의 색인을 사용하여 각 단어를 인코딩합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cea07e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cb201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_index(word):\n",
    "    # 레이블에서 단어 index를 tensor로 반환\n",
    "def index_to_label(index):\n",
    "    # 레이블의 인덱스에 해당하는 단어를 반환\n",
    "# label --> index --> label 변환"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0c630d",
   "metadata": {
    "id": "uQSczk2O0i_J"
   },
   "source": [
    "오디오 녹음 및 발화로 구성된 데이터 포인트 목록을 모델에 대한 두 개의 일괄 텐서로 전환하기 위해 데이터 세트를 일괄적으로 반복할 수 있는 PyTorch DataLoader에서 사용하는 데이터 정렬 함수를 구현합니다.\n",
    "\n",
    "CNN 모델은 주로 입력 형식으로 (batch_size, in_channels, sequence_length)를 요구합니다.\n",
    "이 경우, permute(0, 2, 1)을 사용하면 시퀀스 차원과 특징 차원(feature_size)을 교환하여 CNN이 요구하는 입력 형식 (batch_size, feature_size, sequence_length)로 맞출 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1388e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세 개의 텐서를 패딩하여 동일한 길이로 맞춘 배치 생성\n",
    "# batch_first=True를 설정하면 배치 크기가 첫 번째 차원이 됨, padding_value=0. 으로 0을 사용해 패딩\n",
    "# 패딩된 배치의 크기 출력\n",
    "# 패딩된 배치의 차원을 변환하여 두 번째 차원과 세 번째 차원을 교환한 크기 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3816e",
   "metadata": {
    "id": "AlH-qeXe0OI0"
   },
   "source": [
    "- batch shape 은 nn.Conv1d의 입력에 맞추어 $(N, C_{\\text{in}}, L)$으로 출력  \n",
    "- N: batch size, C: channels, L: sequence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af10bd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequence(batch):\n",
    "    # 0으로 패딩하여 배치 내의 모든 텐서를 동일한 길이로 만듭니다.\n",
    "def collate_fn(batch):\n",
    "    # 데이터 튜플의 형식:\n",
    "    # waveform, sample_rate, label, speaker_id, utterance_number\n",
    "    # 리스트로 데이터를 모으고, 레이블을 인덱스로 인코딩\n",
    "    # 텐서 리스트를 배치 텐서로 그룹화\n",
    "# GPU를 사용할 경우 관련 설정\n",
    "# 학습 데이터 로더 설정\n",
    "# 테스트 데이터 로더 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8345850",
   "metadata": {
    "id": "qFtxhuED0i_L"
   },
   "source": [
    "네트워크 정의\n",
    "------------------\n",
    "\n",
    "원시 오디오 데이터를 처리하기 위해 컨벌루션 신경망을 사용.   \n",
    "일반적으로 더 고급 변환이 오디오 데이터에 적용되지만 CNN을 사용하여 원시 데이터를 정확하게 처리 할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1347947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M5(nn.Module):\n",
    "    def __init__(self, n_input=1, n_output=35, stride=16, n_channel=32):\n",
    "    def forward(self, x):\n",
    "def count_parameters(model):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7611bcc7",
   "metadata": {
    "id": "WN74gQYi0i_M"
   },
   "source": [
    "가중치 감소가 0.0001로 설정된 Adam 옵티마이저를 사용. 처음에는 0.01의 학습률로 훈련하지만 scheduler20 에포크 이후 훈련 중에 ``scheduler`` 를 사용 하여 0.001로 줄입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf342ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight decay: L2 패널티를 적용 (가중치 감쇠)\n",
    "# 학습률 스케줄러 설정\n",
    "# step_size 에포크마다 gamma 비율로 학습률을 감소시킴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb867192",
   "metadata": {
    "id": "4GH59aTo0i_N"
   },
   "source": [
    "네트워크 훈련 및 테스트\n",
    "--------------------------------\n",
    "\n",
    "이제 훈련 데이터를 모델에 공급하고 backpropagation 및 optimization 단계를 수행하는 training 함수를 정의해 보겠습니다. 훈련을 위해 우리가 사용할 손실은 negative log-likelihood입니다. 그런 다음 각 Epoch 후에 네트워크를 테스트하여 훈련 중에 정확도가 어떻게 달라지는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff7843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, log_interval):\n",
    "        # device에서 직접 전체 배치에 변환 및 모델 적용\n",
    "        # (batch x 1 x n_output)에 대한 negative log-likelihood 손실 계산\n",
    "        # 학습 통계 출력\n",
    "        # 진행 상황 바 업데이트\n",
    "        # 손실 기록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d9c1c",
   "metadata": {
    "id": "o_UbMGvc0i_O"
   },
   "source": [
    "이제 training 함수가 있으므로 네트워크 정확도를 테스트하기 위한 함수를 만들어야합니다. 모델을 eval()모드로 설정한 다음 테스트 데이터세트에서 추론을 실행합니다. eval()을 호출하여 네트워크의 모든 모듈에서 훈련 변수를 false로 설정합니다. 배치 정규화 및 드롭 아웃 레이어와 같은 특정 레이어는 훈련 중에 다르게 작동하므로 이 단계는 올바른 결과를 얻는 데 중요합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00209b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_correct(pred, target):\n",
    "    # 정확한 예측의 개수를 셈\n",
    "def get_likely_index(tensor):\n",
    "    # 배치 내 각 요소에 대해 가장 가능성 높은 라벨 인덱스를 찾음\n",
    "def test(model, epoch):\n",
    "        # device에서 직접 전체 배치에 변환 및 모델 적용\n",
    "        # 진행 상황 바 업데이트\n",
    "    # 에포크별 테스트 결과 출력 (정확도)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08797e1",
   "metadata": {
    "id": "u9uyZ9bi0i_P"
   },
   "source": [
    "이제 네트워크를 훈련하고 테스트 할 수 있습니다. 우리는 10  Epoch 동안 네트워크를 훈련시킨 다음, 학습률을 줄이고 10 Epoch 더 훈련할 것입니다. 훈련 중 정확도가 어떻게 달라지는지 확인하기 위해 각 Epoch 후에 네트워크를 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff704448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tqdm을 사용하여 진행 상황 표시\n",
    "# 학습 손실을 반복 횟수에 따라 시각화"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3901bd",
   "metadata": {
    "id": "A9wM9Ium0i_Q"
   },
   "source": [
    "네트워크는 2 Epoch 후에 테스트 세트에서 65 % 이상, 21 Epoch 후에 85 % 이상 정확해야합니다. train 세트의 마지막 단어를보고 모델이 어떻게했는지 살펴 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25b2ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(tensor):\n",
    "    # 모델을 사용하여 파형의 레이블을 예측\n",
    "# 학습 세트에서 마지막 항목의 파형(waveform), 샘플링 속도, 발화(utterance) 가져오기\n",
    "# 오디오 재생 (파형을 numpy 배열로 변환하고 샘플링 속도 설정)\n",
    "# 예측된 결과와 실제 발화 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34685110",
   "metadata": {
    "id": "LIjGOnwg0i_Q"
   },
   "source": [
    "올바르게 분류되지 않은 예를 찾아 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e10ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 파형을 예측하여 출력값을 생성\n",
    "    # 예측값이 실제 발화(utterance)와 다를 경우\n",
    "        # 오디오 재생 (파형을 numpy 배열로 변환하고 샘플링 속도를 적용하여 재생)\n",
    "        # 잘못 분류된 데이터 포인트와 예측 결과 출력\n",
    "        # 모든 예시가 올바르게 분류된 경우 출력\n",
    "        # 잘못된 예시가 없을 경우 마지막 데이터 포인트를 출력\n",
    "        # 마지막 데이터 포인트의 오디오 재생\n",
    "        # 마지막 데이터 포인트의 예상 발화와 예측된 결과 출력"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "009ebc59daac441ca6bcc1f8441919fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "038e098e33524737be092c74067749f0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "10569331639245d28439ac50a832f4f2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2befe2bbbd8444c4b2c941f76c022321": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e78aff299c844aeeb3506aa4a1d1f3d1",
       "IPY_MODEL_e929d07d3ee7458389e1b36efd64494f",
       "IPY_MODEL_ff8999d412664518a1290ded5f550c8f"
      ],
      "layout": "IPY_MODEL_d3d90112b6ba4db48d11bb26f25afe9c"
     }
    },
    "34aef9ef86e64852a513b494ed885a9a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "564d005800cb417495bc211d7af6530c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a29a93e35d5946a887e66aa7c5b40cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3d90112b6ba4db48d11bb26f25afe9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e78aff299c844aeeb3506aa4a1d1f3d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_10569331639245d28439ac50a832f4f2",
      "placeholder": "​",
      "style": "IPY_MODEL_009ebc59daac441ca6bcc1f8441919fb",
      "value": "100%"
     }
    },
    "e929d07d3ee7458389e1b36efd64494f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34aef9ef86e64852a513b494ed885a9a",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_564d005800cb417495bc211d7af6530c",
      "value": 1.9999999999999793
     }
    },
    "ff8999d412664518a1290ded5f550c8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_038e098e33524737be092c74067749f0",
      "placeholder": "​",
      "style": "IPY_MODEL_a29a93e35d5946a887e66aa7c5b40cf5",
      "value": " 1.9999999999999793/2 [13:17&lt;00:00, 380.68s/it]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
