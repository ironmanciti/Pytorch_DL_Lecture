{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ae55c84f",
      "metadata": {
        "id": "ae55c84f"
      },
      "source": [
        "# Autoregressive (자동회귀) 문장 생성\n",
        "\n",
        "- Colab 에서 실행\n",
        "\n",
        "간단한 자동 회귀적인 텍스트 생성을 위한 코드 예제입니다. 여기서는 네이버의 HyperCLOVAX 모델을 사용합니다. HyperCLOVAX는 한국어에 특화된 대화형 언어 모델로, 시스템 메시지와 사용자 메시지를 구분하여 입력받는 구조를 가지고 있습니다. 이는 GPT 계열 모델과 유사한 자동회귀 구조를 가지고 있으므로, 동일한 접근 방식을 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aBc5bQic1YfQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBc5bQic1YfQ",
        "outputId": "d2463036-80d6-4d2c-b0ad-be5ac4dd2f1b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hNNFKA4L31HS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNNFKA4L31HS",
        "outputId": "d324e71b-8cd8-4f81-ddc3-c3afd6710776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "전체 입력 토큰: tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198]], device='cuda:0')\n",
            "토큰 개수: 14\n",
            "전체 디코딩 결과 (special_tokens 포함):\n",
            "<|im_start|>user\n",
            "옛날 옛적에<|im_end|>\n",
            "<|im_start|>assistant\n",
            "\n",
            "옛날 옛적에 토큰: tensor([[ 36092,    249, 104013, 102476,  82068,  19954]])\n",
            "옛날 옛적에 토큰 개수: 6\n",
            "디코딩 결과: 옛날 옛적에\n"
          ]
        }
      ],
      "source": [
        "# 문장 시작 부분\n",
        "system_content = \"\"\n",
        "user_content = \"옛날 옛적에\"\n",
        "chat = [\n",
        "    {\"role\": \"user\", \"content\": user_content},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(chat, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
        "inputs = inputs.to(model.device)\n",
        "\n",
        "# 토큰화 결과 확인\n",
        "print(\"전체 입력 토큰:\", inputs['input_ids'])\n",
        "print(\"토큰 개수:\", inputs['input_ids'].shape[1])\n",
        "\n",
        "# 전체 입력 토큰 디코딩\n",
        "full_tokens = inputs['input_ids']\n",
        "\n",
        "decoded_full = tokenizer.decode(full_tokens[0], skip_special_tokens=False)  # special_tokens도 포함해서 보기\n",
        "print(\"전체 디코딩 결과 (special_tokens 포함):\")\n",
        "print(decoded_full)\n",
        "\n",
        "# user_content 부분만 토큰화해서 확인\n",
        "simple_tokens = tokenizer.encode(f\"{user_content}\", return_tensors=\"pt\")\n",
        "print(f\"{user_content} 토큰:\", simple_tokens)\n",
        "print(f\"{user_content} 토큰 개수:\", simple_tokens.shape[1])\n",
        "\n",
        "# 토큰을 다시 텍스트로 변환해서 확인\n",
        "decoded = tokenizer.decode(simple_tokens[0], skip_special_tokens=True)\n",
        "print(\"디코딩 결과:\", decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jitAS2f34N55",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jitAS2f34N55",
        "outputId": "d2be146c-d715-47d9-b9a5-2d37ac4215e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
              "         100273,    198, 100272,  78191,    198,      1,  36092,    249, 104013,\n",
              "         102476,  82068,  19954,  21908,  16969, 109605, 104967, 102134, 103536,\n",
              "          72043, 104562,     11, 107325, 106763,  57390,  61415, 106439, 107510,\n",
              "         105077, 107468, 101632,     13,  23955, 107367, 105012, 104065,  81673,\n",
              "         110211, 101721, 110288,     11, 104690, 108693,  54780, 109130,  21028,\n",
              "          66610, 104685, 105873,  35495, 101632,    382, 106900, 110125,    330,\n",
              "         108606, 107699,  66965,    498,    330, 104765, 106889,  66965,    498,\n",
              "            330, 103339,  64189,  66965,      1, 106484, 109344,     11, 102388,\n",
              "         105378, 104304, 103400,  81673, 101942,  18359, 105928, 107505, 101888,\n",
              "         110125, 101074, 107097,  81673, 104284, 103049, 109686, 102520, 101632,\n",
              "             13]], device='cuda:0')"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 문장 생성\n",
        "output_ids = model.generate(\n",
        "    **inputs,    # inputs 딕셔너리를 언패킹해서 전달\n",
        "    max_length=100,\n",
        "    num_return_sequences=1,\n",
        "    repetition_penalty=1.2,  # 반복 패널티\n",
        "    eos_token_id=tokenizer.eos_token_id,\n",
        "    pad_token_id=tokenizer.eos_token_id\n",
        ")\n",
        "output_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zVmTwgeQ4WpE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVmTwgeQ4WpE",
        "outputId": "4cd755ea-f6cd-4a16-8919-c90d247acf52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated text: user\n",
            "옛날 옛적에\n",
            "assistant\n",
            "\"옛날 옛적에...\"는 한국 전통 문학 작품 중 하나로, 주로 신화나 전설적인 이야기를 담고 있습니다. 이 작품은 다양한 문화와 시대를 배경으로 하며, 인간의 삶과 자연의 조화를 다루고 있습니다.\n",
            "\n",
            "대표적으로 \"춘향전\", \"심청전\", \"흥부전\" 등이 있으며, 이들은 각각 다른 시대와 배경을 가지고 있지만 공통적으로 인간 관계와 도덕성을 강조하고 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# 생성된 문장 출력 (CLOVAX 방식)\n",
        "output_text = tokenizer.batch_decode(output_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "# 필요시 <|endofturn|>, <|stop|> 등에서 자르기\n",
        "for stop_str in [\"<|endofturn|>\", \"<|stop|>\"]:\n",
        "    if stop_str in output_text:\n",
        "        output_text = output_text.split(stop_str)[0]\n",
        "\n",
        "print(f\"Generated text: {output_text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c10e2ff5",
      "metadata": {
        "id": "c10e2ff5"
      },
      "source": [
        "HyperCLOVAX는 자체적으로 autoregressive 모델입니다. \"Autoregressive\"란, 이전에 생성된 토큰들을 기반으로 다음 토큰을 생성하는 모델을 의미합니다.\n",
        "\n",
        "위의 코드에서 `model.generate` 메서드는 이미 autoregressive한 방식으로 문장을 생성합니다. 그러나 이를 명시적으로 보여주기 위해 각 단계에서 토큰을 하나씩 생성하는 autoregressive한 코드를 아래에 작성하겠습니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7kRgp_2C48PJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kRgp_2C48PJ",
        "outputId": "5161bce0-f69e-4eea-f6ef-553e9cb2b7aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
              "         100273,    198, 100272,  78191,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 문장 시작 부분\n",
        "user_content = \"옛날 옛적에\"\n",
        "chat = [\n",
        "    {\"role\": \"user\", \"content\": user_content},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(chat, add_generation_prompt=True, return_dict=True, return_tensors=\"pt\")\n",
        "inputs = inputs.to(model.device)\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ut71Jnk5TnK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ut71Jnk5TnK",
        "outputId": "4295f5cb-52d0-459b-bc39-506d6b061fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 14, 110592])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([[[-1.4064, -0.9157, -0.1506,  ..., -1.1698, -1.1692, -1.1691],\n",
              "         [ 9.2706, 12.9401, 11.9009,  ...,  3.7357,  3.7357,  3.7366],\n",
              "         [ 6.2054,  9.7094, 10.5673,  ..., -0.0378, -0.0385, -0.0376],\n",
              "         ...,\n",
              "         [ 3.6117,  2.1378,  9.5609,  ...,  0.8532,  0.8533,  0.8542],\n",
              "         [10.9762,  9.0058,  9.4168,  ...,  3.4993,  3.4983,  3.4996],\n",
              "         [ 8.0550, 19.3332, 13.4940,  ...,  1.6563,  1.6563,  1.6562]]],\n",
              "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 모델 추론\n",
        "predictions = model(**inputs)  # inputs 딕셔너리를 언패킹해서 전달\n",
        "logits = predictions.logits\n",
        "print(logits.shape)\n",
        "logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IMhQdaVO5re0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMhQdaVO5re0",
        "outputId": "5dc7b397-7a11-40a6-9637-3a33cb0045ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575, 105469]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575, 105469, 108978]],\n",
            "       device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575, 105469, 108978,\n",
            "          36439]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575, 105469, 108978,\n",
            "          36439,  13879]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575, 105469, 108978,\n",
            "          36439,  13879,  90463]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575, 105469, 108978,\n",
            "          36439,  13879,  90463,     13]], device='cuda:0')\n",
            "tensor([[100272,    882,    198,  36092,    249, 104013, 102476,  82068,  19954,\n",
            "         100273,    198, 100272,  78191,    198,  36092,    249, 104013, 102476,\n",
            "          82068,  19954,     11, 101855, 107867,  19954,  62398, 105518, 108950,\n",
            "         100600,  36439,  13879,  90463,     13, 100863, 107867,  21028, 109720,\n",
            "          19954,  65621, 105972, 105761,  91834, 109675,  57575, 105469, 108978,\n",
            "          36439,  13879,  90463,     13,  55925]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Autoregressive한 방식으로 문장 생성\n",
        "max_length = 50\n",
        "input_ids_concat = inputs['input_ids'].clone()  # inputs에서 input_ids 추출\n",
        "\n",
        "while input_ids_concat.shape[1] < max_length:\n",
        "    # 다음 토큰 예측\n",
        "    model_inputs = {'input_ids': input_ids_concat}\n",
        "    if 'attention_mask' in inputs:\n",
        "        model_inputs['attention_mask'] = torch.ones_like(input_ids_concat)\n",
        "\n",
        "    predictions = model(**model_inputs)\n",
        "    logits = predictions.logits\n",
        "    predicted_token = torch.argmax(logits[0, -1]).item()\n",
        "    #print(predicted_token)\n",
        "\n",
        "    # 생성된 토큰을 입력 토큰 뒤에 추가\n",
        "    input_ids_concat = torch.cat([input_ids_concat, torch.tensor([[predicted_token]], device=input_ids_concat.device)], dim=1)\n",
        "    print(input_ids_concat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "573d7029",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "573d7029",
        "outputId": "8ae668d6-ccdd-4684-93bc-7614c4436470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user\n",
            "옛날 옛적에\n",
            "assistant\n",
            "옛날 옛적에, 어느 마을에 한 소년이 살고 있었습니다. 그는 마을의 중심에 있는 큰 나무 아래에서 책을 읽고 있었습니다. 그\n"
          ]
        }
      ],
      "source": [
        "# 생성된 문장 출력\n",
        "decoded_text = tokenizer.decode(input_ids_concat[0], skip_special_tokens=True)\n",
        "\n",
        "# 필요시 <|endofturn|>, <|stop|> 등에서 자르기\n",
        "for stop_str in [\"<|endofturn|>\", \"<|stop|>\"]:\n",
        "    if stop_str in decoded_text:\n",
        "        decoded_text = decoded_text.split(stop_str)[0]\n",
        "\n",
        "print(decoded_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "O3E_DXy0Na-0",
      "metadata": {
        "id": "O3E_DXy0Na-0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}